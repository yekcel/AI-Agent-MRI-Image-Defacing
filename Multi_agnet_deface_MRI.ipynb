{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgNpcdk3RWzR8adAZuzHQp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yekcel/AI-Agent-MRI-Image-Defacing/blob/main/Multi_agnet_deface_MRI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g74_P-U2ts_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f55fd01-24ab-4081-e748-88cf0e0e5608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.4/1.2 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q ultralytics opencv-python google-generativeai pillow numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import google.generativeai as genai\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import json\n",
        "from datetime import datetime\n"
      ],
      "metadata": {
        "id": "zAm1EFwErys_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Get API key from Colab secrets\n",
        "GEMINI_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# Configure Gemini\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Initialize Gemini model\n",
        "gemini_model = genai.GenerativeModel('gemini-2.0-flash-exp')\n",
        "\n",
        "print(\"âœ… Gemini API configured successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxGZfzhuyV1w",
        "outputId": "47549567-ab0c-4cb0-b6e8-d1df85269bc1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Gemini API configured successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create necessary directories\n",
        "Path(\"input_images\").mkdir(exist_ok=True)\n",
        "Path(\"output_images\").mkdir(exist_ok=True)\n",
        "Path(\"logs\").mkdir(exist_ok=True)\n",
        "\n",
        "print(\"âœ… Directories created:\")\n",
        "print(\"   â€¢ input_images/\")\n",
        "print(\"   â€¢ output_images/\")\n",
        "print(\"   â€¢ logs/\")\n"
      ],
      "metadata": {
        "id": "DgHDyk_hrwuM",
        "outputId": "34adfca2-a4a9-4dd6-db5f-caa537b328d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Directories created:\n",
            "   â€¢ input_images/\n",
            "   â€¢ output_images/\n",
            "   â€¢ logs/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "print(\"ğŸ“¥ Downloading YOLO face detection model...\\n\")\n",
        "\n",
        "MODEL_URL = \"https://github.com/yekcel/AI-Agent-MRI-Image-Defacing/raw/main/model_outputs/best_model.pt\"\n",
        "MODEL_PATH = \"yolo_face_detector.pt\"\n",
        "\n",
        "try:\n",
        "    response = requests.get(MODEL_URL, timeout=60)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    with open(MODEL_PATH, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "    file_size = os.path.getsize(MODEL_PATH)\n",
        "    print(f\"âœ… Model downloaded successfully!\")\n",
        "    print(f\"   Size: {file_size:,} bytes\")\n",
        "    print(f\"   Path: {MODEL_PATH}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error downloading model: {str(e)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-YISEbPzLNx",
        "outputId": "b3d67b61-b21d-4a69-dd99-812640e10d53"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¥ Downloading YOLO face detection model...\n",
            "\n",
            "âœ… Model downloaded successfully!\n",
            "   Size: 5,471,386 bytes\n",
            "   Path: yolo_face_detector.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DetectorAgent:\n",
        "    \"\"\"\n",
        "    Agent responsible for detecting faces in MRI images using YOLO.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_path: str = \"yolo_face_detector.pt\", confidence: float = 0.3):\n",
        "        \"\"\"\n",
        "        Initialize the detector agent.\n",
        "\n",
        "        Args:\n",
        "            model_path: Path to YOLO model weights\n",
        "            confidence: Detection confidence threshold\n",
        "        \"\"\"\n",
        "        self.model_path = model_path\n",
        "        self.confidence = confidence\n",
        "        self.model = None\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load the YOLO model.\"\"\"\n",
        "        if self.model is None:\n",
        "            self.model = YOLO(self.model_path)\n",
        "            print(f\"âœ… DetectorAgent: Loaded YOLO model from {self.model_path}\")\n",
        "\n",
        "    def detect(self, image: np.ndarray) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Detect faces in the image.\n",
        "\n",
        "        Args:\n",
        "            image: Grayscale MRI image\n",
        "\n",
        "        Returns:\n",
        "            List of detection dictionaries with bbox and confidence\n",
        "        \"\"\"\n",
        "        self.load_model()\n",
        "\n",
        "        # Convert grayscale to RGB for YOLO\n",
        "        if len(image.shape) == 2:\n",
        "            image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "        else:\n",
        "            image_rgb = image\n",
        "\n",
        "        # Run detection\n",
        "        results = self.model(image_rgb, conf=self.confidence, verbose=False)\n",
        "\n",
        "        detections = []\n",
        "        for box in results[0].boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
        "            conf = box.conf[0].item()\n",
        "\n",
        "            detections.append({\n",
        "                'bbox': (x1, y1, x2, y2),\n",
        "                'confidence': conf\n",
        "            })\n",
        "\n",
        "        return detections\n",
        "\n",
        "print(\"âœ… DetectorAgent class defined\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-mrU-ByzXKM",
        "outputId": "5f013e62-654f-4be7-e9ec-7fd25b92d87b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… DetectorAgent class defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DefacerAgent:\n",
        "    \"\"\"\n",
        "    Agent responsible for applying non-reversible defacing strategies.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the defacer agent.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def deface(self, image: np.ndarray, bbox: Tuple[int, int, int, int],\n",
        "               strategy: str = \"gentle\") -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Apply defacing strategy to the detected face region.\n",
        "\n",
        "        Args:\n",
        "            image: Original grayscale MRI image\n",
        "            bbox: Bounding box (x1, y1, x2, y2)\n",
        "            strategy: One of ['gentle', 'moderate', 'maximum', 'skull_strip']\n",
        "\n",
        "        Returns:\n",
        "            Defaced image\n",
        "        \"\"\"\n",
        "        result_image = image.copy()\n",
        "        x1, y1, x2, y2 = bbox\n",
        "\n",
        "        # Ensure coordinates are within image bounds\n",
        "        h, w = image.shape[:2]\n",
        "        x1, y1 = max(0, x1), max(0, y1)\n",
        "        x2, y2 = min(w, x2), min(h, y2)\n",
        "\n",
        "        if strategy == \"gentle\":\n",
        "            # Inpainting using Telea algorithm\n",
        "            mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
        "            mask[y1:y2, x1:x2] = 255\n",
        "            result_image = cv2.inpaint(result_image, mask, 3, cv2.INPAINT_TELEA)\n",
        "\n",
        "        elif strategy == \"moderate\":\n",
        "            # Random texture fill from surrounding pixels\n",
        "            surrounding = []\n",
        "            pad = 10\n",
        "            if y1 > pad:\n",
        "                surrounding.append(image[y1-pad:y1, x1:x2])\n",
        "            if y2 < h - pad:\n",
        "                surrounding.append(image[y2:y2+pad, x1:x2])\n",
        "            if x1 > pad:\n",
        "                surrounding.append(image[y1:y2, x1-pad:x1])\n",
        "            if x2 < w - pad:\n",
        "                surrounding.append(image[y1:y2, x2:x2+pad])\n",
        "\n",
        "            if surrounding:\n",
        "                texture = np.concatenate([s.flatten() for s in surrounding])\n",
        "                random_fill = np.random.choice(texture, size=(y2-y1, x2-x1))\n",
        "                result_image[y1:y2, x1:x2] = random_fill\n",
        "            else:\n",
        "                result_image[y1:y2, x1:x2] = 0\n",
        "\n",
        "        elif strategy == \"maximum\":\n",
        "            # Black box (complete removal)\n",
        "            result_image[y1:y2, x1:x2] = 0\n",
        "\n",
        "        elif strategy == \"skull_strip\":\n",
        "            # Extended removal towards skull\n",
        "            expansion = int((x2 - x1) * 0.3)\n",
        "            y1_ext = max(0, y1 - expansion)\n",
        "            y2_ext = min(h, y2 + expansion // 2)\n",
        "            x1_ext = max(0, x1 - expansion // 2)\n",
        "            x2_ext = min(w, x2 + expansion // 2)\n",
        "\n",
        "            result_image[y1_ext:y2_ext, x1_ext:x2_ext] = 0\n",
        "\n",
        "        return result_image\n",
        "\n",
        "print(\"âœ… DefacerAgent class defined\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSeKxdEDzdy8",
        "outputId": "1d2fc5e3-ab0e-42da-e4d0-b05cc8b7cafb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… DefacerAgent class defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ValidatorAgent:\n",
        "    \"\"\"\n",
        "    Agent responsible for validating defaced images (ensuring no faces remain).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_path: str = \"yolo_face_detector.pt\", confidence: float = 0.1):\n",
        "        \"\"\"\n",
        "        Initialize the validator agent.\n",
        "\n",
        "        Args:\n",
        "            model_path: Path to YOLO model weights\n",
        "            confidence: Lower confidence threshold for validation\n",
        "        \"\"\"\n",
        "        self.model_path = model_path\n",
        "        self.confidence = confidence\n",
        "        self.model = None\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load the YOLO model.\"\"\"\n",
        "        if self.model is None:\n",
        "            self.model = YOLO(self.model_path)\n",
        "            print(f\"âœ… ValidatorAgent: Loaded YOLO model\")\n",
        "\n",
        "    def validate(self, image: np.ndarray, threshold: float = 0.3) -> Dict:\n",
        "        \"\"\"\n",
        "        Validate that no faces remain in the defaced image.\n",
        "\n",
        "        Args:\n",
        "            image: Defaced grayscale MRI image\n",
        "            threshold: Maximum acceptable confidence for remaining faces\n",
        "\n",
        "        Returns:\n",
        "            Validation result dictionary\n",
        "        \"\"\"\n",
        "        self.load_model()\n",
        "\n",
        "        # Convert grayscale to RGB for YOLO\n",
        "        if len(image.shape) == 2:\n",
        "            image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "        else:\n",
        "            image_rgb = image\n",
        "\n",
        "        # Run detection with lower confidence\n",
        "        results = self.model(image_rgb, conf=self.confidence, verbose=False)\n",
        "\n",
        "        detections = []\n",
        "        max_confidence = 0.0\n",
        "\n",
        "        for box in results[0].boxes:\n",
        "            conf = box.conf[0].item()\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
        "\n",
        "            detections.append({\n",
        "                'bbox': (x1, y1, x2, y2),\n",
        "                'confidence': conf\n",
        "            })\n",
        "\n",
        "            max_confidence = max(max_confidence, conf)\n",
        "\n",
        "        # Validation passes if no high-confidence faces remain\n",
        "        is_valid = max_confidence < threshold\n",
        "\n",
        "        return {\n",
        "            'is_valid': is_valid,\n",
        "            'detections': detections,\n",
        "            'max_confidence': max_confidence,\n",
        "            'num_faces': len(detections)\n",
        "        }\n",
        "\n",
        "print(\"âœ… ValidatorAgent class defined\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wauxutS3odpD",
        "outputId": "dfde17be-fd2d-4b43-e734-c7379232bf38"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ValidatorAgent class defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GeminiStrategyAgent:\n",
        "    \"\"\"\n",
        "    Agent that uses Gemini API to intelligently select defacing strategies.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model):\n",
        "        \"\"\"\n",
        "        Initialize the Gemini strategy agent.\n",
        "\n",
        "        Args:\n",
        "            model: Gemini generative model instance\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "\n",
        "    def decide_strategy(self, iteration: int, validation_result: Optional[Dict] = None,\n",
        "                       previous_strategy: Optional[str] = None) -> str:\n",
        "        \"\"\"\n",
        "        Use Gemini to decide the next defacing strategy.\n",
        "\n",
        "        Args:\n",
        "            iteration: Current iteration number (1-4)\n",
        "            validation_result: Result from ValidatorAgent (None for first iteration)\n",
        "            previous_strategy: Previously used strategy\n",
        "\n",
        "        Returns:\n",
        "            Strategy name: 'gentle', 'moderate', 'maximum', or 'skull_strip'\n",
        "        \"\"\"\n",
        "\n",
        "        # Build prompt for Gemini\n",
        "        if iteration == 1:\n",
        "            prompt = \"\"\"You are an AI agent helping to deface MRI images for privacy protection.\n",
        "This is the FIRST attempt. Choose the best non-reversible defacing strategy from:\n",
        "- gentle: Inpainting (subtle, tries to blend)\n",
        "- moderate: Random texture fill (medium)\n",
        "- maximum: Black box (complete removal)\n",
        "- skull_strip: Extended removal towards skull\n",
        "\n",
        "Choose ONE strategy. Respond with ONLY the strategy name.\"\"\"\n",
        "\n",
        "        else:\n",
        "            max_conf = validation_result.get('max_confidence', 0.0)\n",
        "            num_faces = validation_result.get('num_faces', 0)\n",
        "\n",
        "            prompt = f\"\"\"You are an AI agent helping to deface MRI images for privacy protection.\n",
        "\n",
        "ITERATION {iteration}/4\n",
        "Previous strategy: {previous_strategy}\n",
        "Validation result: {num_faces} faces detected, max confidence: {max_conf:.3f}\n",
        "\n",
        "The previous strategy FAILED. Choose a MORE AGGRESSIVE non-reversible strategy from:\n",
        "- gentle: Inpainting\n",
        "- moderate: Random texture fill\n",
        "- maximum: Black box\n",
        "- skull_strip: Extended removal\n",
        "\n",
        "IMPORTANT: Choose a strategy MORE AGGRESSIVE than '{previous_strategy}'.\n",
        "\n",
        "Respond with ONLY the strategy name.\"\"\"\n",
        "\n",
        "        # Call Gemini\n",
        "        response = self.model.generate_content(prompt)\n",
        "        strategy = response.text.strip().lower()\n",
        "\n",
        "        # Validate response\n",
        "        valid_strategies = ['gentle', 'moderate', 'maximum', 'skull_strip']\n",
        "        if strategy not in valid_strategies:\n",
        "            # Fallback logic\n",
        "            strategy_order = ['gentle', 'moderate', 'maximum', 'skull_strip']\n",
        "            if previous_strategy and previous_strategy in strategy_order:\n",
        "                idx = strategy_order.index(previous_strategy)\n",
        "                strategy = strategy_order[min(idx + 1, len(strategy_order) - 1)]\n",
        "            else:\n",
        "                strategy = strategy_order[min(iteration - 1, len(strategy_order) - 1)]\n",
        "\n",
        "        return strategy\n",
        "\n",
        "print(\"âœ… GeminiStrategyAgent class defined\")\n"
      ],
      "metadata": {
        "id": "hI66N7qgq9-E",
        "outputId": "d312537d-f736-4560-eb66-575e16be7c92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… GeminiStrategyAgent class defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiAgentOrchestrator:\n",
        "    \"\"\"\n",
        "    Orchestrator that coordinates all agents in the defacing pipeline.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_iterations: int = 4, validation_threshold: float = 0.3):\n",
        "        \"\"\"\n",
        "        Initialize the orchestrator.\n",
        "\n",
        "        Args:\n",
        "            max_iterations: Maximum number of defacing attempts\n",
        "            validation_threshold: Confidence threshold for validation\n",
        "        \"\"\"\n",
        "        self.detector = DetectorAgent()\n",
        "        self.defacer = DefacerAgent()\n",
        "        self.validator = ValidatorAgent()  # âœ… Ø­Ø°Ù threshold Ø§Ø² Ø§ÛŒÙ†Ø¬Ø§\n",
        "        self.strategy_agent = GeminiStrategyAgent(gemini_model)\n",
        "\n",
        "        self.max_iterations = max_iterations\n",
        "        self.validation_threshold = validation_threshold\n",
        "\n",
        "    def run(self, image_path: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Run the complete multi-agent defacing pipeline.\n",
        "\n",
        "        Args:\n",
        "            image_path: Path to input MRI image\n",
        "\n",
        "        Returns:\n",
        "            Result dictionary with status, defaced image, and metadata\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ğŸš€ Starting Multi-Agent Defacing Pipeline\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "        # Load image\n",
        "        original_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if original_image is None:\n",
        "            return {'status': 'error', 'message': 'Failed to load image'}\n",
        "\n",
        "        print(f\"ğŸ“¸ Image loaded: {original_image.shape}\")\n",
        "\n",
        "        # Step 1: Initial Detection\n",
        "        print(f\"\\nğŸ” Step 1: Initial Face Detection\")\n",
        "        detections = self.detector.detect(original_image)\n",
        "\n",
        "        if not detections:\n",
        "            print(\"   â„¹ï¸  No faces detected - image is already defaced/clean\")\n",
        "            return {\n",
        "                'status': 'no_faces',\n",
        "                'defaced_image': original_image,\n",
        "                'iterations': 0,\n",
        "                'strategies_used': []\n",
        "            }\n",
        "\n",
        "        print(f\"   âœ… Detected {len(detections)} face(s)\")\n",
        "        for i, det in enumerate(detections, 1):\n",
        "            print(f\"      Face {i}: confidence={det['confidence']:.3f}, bbox={det['bbox']}\")\n",
        "\n",
        "        # Iterative defacing loop\n",
        "        current_image = original_image.copy()\n",
        "        strategies_used = []\n",
        "        previous_strategy = None\n",
        "        validation_result = None\n",
        "\n",
        "        for iteration in range(1, self.max_iterations + 1):\n",
        "            print(f\"\\n{'â”€'*60}\")\n",
        "            print(f\"ğŸ”„ Iteration {iteration}/{self.max_iterations}\")\n",
        "            print(f\"{'â”€'*60}\")\n",
        "\n",
        "            # Step 2: Gemini decides strategy\n",
        "            print(f\"\\nğŸ§  Step 2: Gemini Strategy Selection\")\n",
        "            strategy = self.strategy_agent.decide_strategy(\n",
        "                iteration=iteration,\n",
        "                validation_result=validation_result,\n",
        "                previous_strategy=previous_strategy\n",
        "            )\n",
        "            print(f\"   ğŸ“‹ Selected strategy: '{strategy}'\")\n",
        "            strategies_used.append(strategy)\n",
        "\n",
        "            # Step 3: Apply defacing\n",
        "            print(f\"\\nâœ‚ï¸  Step 3: Applying Defacing\")\n",
        "            for det in detections:\n",
        "                current_image = self.defacer.deface(\n",
        "                    current_image,\n",
        "                    det['bbox'],\n",
        "                    strategy=strategy\n",
        "                )\n",
        "            print(f\"   âœ… Defacing applied with '{strategy}' strategy\")\n",
        "\n",
        "            # Step 4: Validate result\n",
        "            print(f\"\\nâœ”ï¸  Step 4: Validation\")\n",
        "            validation_result = self.validator.validate(\n",
        "                current_image,\n",
        "                threshold=self.validation_threshold  # âœ… threshold Ø±Ùˆ Ø§ÛŒÙ†Ø¬Ø§ Ù¾Ø§Ø³ Ù…ÛŒâ€ŒØ¯ÛŒÙ…\n",
        "            )\n",
        "\n",
        "            print(f\"   Faces detected: {validation_result['num_faces']}\")\n",
        "            print(f\"   Max confidence: {validation_result['max_confidence']:.3f}\")\n",
        "            print(f\"   Threshold: {self.validation_threshold}\")\n",
        "\n",
        "            if validation_result['is_valid']:\n",
        "                print(f\"   âœ… Validation PASSED!\")\n",
        "                print(f\"\\n{'='*60}\")\n",
        "                print(f\"âœ… SUCCESS - Image successfully defaced in {iteration} iteration(s)\")\n",
        "                print(f\"{'='*60}\")\n",
        "                return {\n",
        "                    'status': 'success',\n",
        "                    'defaced_image': current_image,\n",
        "                    'iterations': iteration,\n",
        "                    'strategies_used': strategies_used,\n",
        "                    'final_confidence': validation_result['max_confidence']\n",
        "                }\n",
        "            else:\n",
        "                print(f\"   âŒ Validation FAILED - trying next iteration\")\n",
        "\n",
        "            previous_strategy = strategy\n",
        "\n",
        "        # Max iterations reached\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"âš ï¸  MAX ITERATIONS REACHED - Image may not be fully defaced\")\n",
        "        print(f\"{'='*60}\")\n",
        "        return {\n",
        "            'status': 'max_iterations',\n",
        "            'defaced_image': current_image,\n",
        "            'iterations': self.max_iterations,\n",
        "            'strategies_used': strategies_used,\n",
        "            'final_confidence': validation_result['max_confidence']\n",
        "        }\n",
        "\n",
        "print(\"âœ… MultiAgentOrchestrator class defined\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXBDWOlI3_wM",
        "outputId": "bce2856f-1d61-4bc5-9dac-0a8907a16037"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… MultiAgentOrchestrator class defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"ğŸ“¥ Downloading test MRI images from GitHub...\")\n",
        "\n",
        "# Create input folder\n",
        "Path(\"input_images\").mkdir(exist_ok=True)\n",
        "\n",
        "# Correct RAW URLs for test images\n",
        "TEST_IMAGE_URLS = [\n",
        "    \"https://github.com/yekcel/AI-Agent-MRI-Image-Defacing/raw/main/test_data/images/dicom_000209_jpg.rf.68d7b19c0c5017332d18516147668c4f.jpg\",\n",
        "    \"https://github.com/yekcel/AI-Agent-MRI-Image-Defacing/raw/main/test_data/images/dicom_000218_jpg.rf.2d70d50536d38f2bfa4bd4699955db8b.jpg\",\n",
        "    \"https://github.com/yekcel/AI-Agent-MRI-Image-Defacing/raw/main/test_data/images/dicom_002284_jpg.rf.0ef17c3c1c6d85b222e00e3ec887c8ce.jpg\",\n",
        "]\n",
        "\n",
        "success_count = 0\n",
        "\n",
        "for idx, url in enumerate(TEST_IMAGE_URLS, 1):\n",
        "    filename = url.split('/')[-1]\n",
        "    print(f\"   [{idx}/{len(TEST_IMAGE_URLS)}] Downloading {filename[:50]}...\")\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, timeout=30)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Save file\n",
        "        save_path = f\"input_images/{filename}\"\n",
        "        with open(save_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "\n",
        "        file_size = len(response.content)\n",
        "        print(f\"      âœ… Saved ({file_size:,} bytes)\")\n",
        "        success_count += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"      âŒ Error: {str(e)}\")\n",
        "\n",
        "print(f\"\\nâœ… Successfully downloaded {success_count}/{len(TEST_IMAGE_URLS)} images!\")\n",
        "\n",
        "# List downloaded images\n",
        "files = os.listdir(\"input_images\")\n",
        "if files:\n",
        "    print(f\"\\nğŸ“ Files in input_images/:\")\n",
        "    for f in files:\n",
        "        size = os.path.getsize(f\"input_images/{f}\")\n",
        "        print(f\"   â€¢ {f[:50]} ({size:,} bytes)\")\n"
      ],
      "metadata": {
        "id": "uDWYZzVguGx6",
        "outputId": "6d2d347d-7ff3-4ecb-8abc-4483facfbd81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¥ Downloading test MRI images from GitHub...\n",
            "   [1/3] Downloading dicom_000209_jpg.rf.68d7b19c0c5017332d18516147668c...\n",
            "      âœ… Saved (26,364 bytes)\n",
            "   [2/3] Downloading dicom_000218_jpg.rf.2d70d50536d38f2bfa4bd4699955db...\n",
            "      âœ… Saved (24,814 bytes)\n",
            "   [3/3] Downloading dicom_002284_jpg.rf.0ef17c3c1c6d85b222e00e3ec887c8...\n",
            "      âœ… Saved (21,033 bytes)\n",
            "\n",
            "âœ… Successfully downloaded 3/3 images!\n",
            "\n",
            "ğŸ“ Files in input_images/:\n",
            "   â€¢ dicom_000209_jpg.rf.68d7b19c0c5017332d18516147668c (26,364 bytes)\n",
            "   â€¢ dicom_000218_jpg.rf.2d70d50536d38f2bfa4bd4699955db (24,814 bytes)\n",
            "   â€¢ dicom_002284_jpg.rf.0ef17c3c1c6d85b222e00e3ec887c8 (21,033 bytes)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "print(\"ğŸ§ª Testing YOLO model on downloaded images...\\n\")\n",
        "\n",
        "model = YOLO(\"yolo_face_detector.pt\")\n",
        "\n",
        "# Get first image\n",
        "images = [f for f in os.listdir(\"input_images\") if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "if not images:\n",
        "    print(\"âŒ No images found in input_images/\")\n",
        "else:\n",
        "    test_image_path = f\"input_images/{images[0]}\"\n",
        "    print(f\"Testing on: {images[0]}\")\n",
        "\n",
        "    # Load image as grayscale\n",
        "    img_gray = cv2.imread(test_image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if img_gray is None:\n",
        "        print(\"âŒ Failed to load image!\")\n",
        "    else:\n",
        "        print(f\"   âœ… Image loaded: {img_gray.shape} (grayscale)\")\n",
        "\n",
        "        # Convert grayscale to RGB (YOLO needs 3 channels)\n",
        "        img_rgb = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB)\n",
        "        print(f\"   ğŸ”„ Converted to RGB: {img_rgb.shape}\")\n",
        "\n",
        "        # Run detection\n",
        "        results = model(img_rgb, conf=0.3, verbose=False)\n",
        "\n",
        "        if len(results[0].boxes) > 0:\n",
        "            print(f\"   âœ… Detected {len(results[0].boxes)} face(s)\")\n",
        "            for i, box in enumerate(results[0].boxes, 1):\n",
        "                conf = box.conf[0].item()\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
        "                print(f\"      Face {i}: confidence={conf:.3f}, bbox=({x1},{y1},{x2},{y2})\")\n",
        "        else:\n",
        "            print(\"   âš ï¸  No faces detected\")\n",
        "            print(\"      Try lowering confidence threshold\")\n"
      ],
      "metadata": {
        "id": "qS57MZNKuOuD",
        "outputId": "b0f090d2-7862-49b6-c411-bb3624eb8b78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§ª Testing YOLO model on downloaded images...\n",
            "\n",
            "Testing on: dicom_000209_jpg.rf.68d7b19c0c5017332d18516147668c4f.jpg\n",
            "   âœ… Image loaded: (512, 512) (grayscale)\n",
            "   ğŸ”„ Converted to RGB: (512, 512, 3)\n",
            "   âœ… Detected 1 face(s)\n",
            "      Face 1: confidence=0.689, bbox=(41,210,173,415)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the orchestrator\n",
        "orchestrator = MultiAgentOrchestrator(\n",
        "    max_iterations=4,\n",
        "    validation_threshold=0.3\n",
        ")\n",
        "\n",
        "print(\"\\nâœ… Orchestrator ready to process images!\")\n",
        "print(f\"   â€¢ Max iterations: 4\")\n",
        "print(f\"   â€¢ Validation threshold: 0.3 confidence\")\n"
      ],
      "metadata": {
        "id": "1XmIhP2VuU4z",
        "outputId": "aa7569da-7d0c-4ce4-ff95-1a4f033b2e00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Orchestrator ready to process images!\n",
            "   â€¢ Max iterations: 4\n",
            "   â€¢ Validation threshold: 0.3 confidence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Get list of input images\n",
        "input_images = sorted([f for f in os.listdir(\"input_images\")\n",
        "                       if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "\n",
        "if not input_images:\n",
        "    print(\"âŒ No images found in input_images/ folder!\")\n",
        "else:\n",
        "    # Process first image as test\n",
        "    test_image = input_images[0]\n",
        "    test_path = f\"input_images/{test_image}\"\n",
        "\n",
        "    print(f\"ğŸ¯ Processing test image: {test_image}\\n\")\n",
        "\n",
        "    result = orchestrator.run(test_path)\n",
        "\n",
        "    # Save result\n",
        "    if 'defaced_image' in result:\n",
        "        output_path = f\"output_images/defaced_{test_image}\"\n",
        "        cv2.imwrite(output_path, result['defaced_image'])\n",
        "        print(f\"\\nğŸ’¾ Saved to: {output_path}\")\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"ğŸ“Š PROCESSING SUMMARY\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Status: {result['status']}\")\n",
        "    print(f\"Iterations: {result.get('iterations', 0)}\")\n",
        "    print(f\"Strategies used: {' â†’ '.join(result.get('strategies_used', []))}\")\n",
        "    if 'final_confidence' in result:\n",
        "        print(f\"Final confidence: {result['final_confidence']:.3f}\")\n",
        "    print(f\"{'='*60}\")\n"
      ],
      "metadata": {
        "id": "UIP72YtcuYVI",
        "outputId": "e5b5b135-a034-4fc0-8523-aba663488ecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¯ Processing test image: dicom_000209_jpg.rf.68d7b19c0c5017332d18516147668c4f.jpg\n",
            "\n",
            "\n",
            "============================================================\n",
            "ğŸš€ Starting Multi-Agent Defacing Pipeline\n",
            "============================================================\n",
            "\n",
            "ğŸ“¸ Image loaded: (512, 512)\n",
            "\n",
            "ğŸ” Step 1: Initial Face Detection\n",
            "   âœ… Detected 1 face(s)\n",
            "      Face 1: confidence=0.689, bbox=(41, 210, 173, 415)\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ”„ Iteration 1/4\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "ğŸ§  Step 2: Gemini Strategy Selection\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 884.72ms\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TooManyRequests",
          "evalue": "429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-exp\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\nPlease retry in 51.527728161s.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3002243342.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ğŸ¯ Processing test image: {test_image}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morchestrator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Save result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1349153794.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, image_path)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m# Step 2: Gemini decides strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nğŸ§  Step 2: Gemini Strategy Selection\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             strategy = self.strategy_agent.decide_strategy(\n\u001b[0m\u001b[1;32m     74\u001b[0m                 \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mvalidation_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-880069057.py\u001b[0m in \u001b[0;36mdecide_strategy\u001b[0;34m(self, iteration, validation_result, previous_strategy)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Call Gemini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1159\u001b[0m             \u001b[0;31m# subclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mcore_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0;31m# Return the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTooManyRequests\u001b[0m: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-exp\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\nPlease retry in 51.527728161s."
          ]
        }
      ]
    }
  ]
}